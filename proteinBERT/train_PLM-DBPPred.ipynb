{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb066e1-9e1f-40ab-aeba-5671a3d8b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The examples in this notebook use a set of nine benchmarks described in our publication.\n",
    "# These benchmarks can be downloaded via FTP from: ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks\n",
    "# Download the benchmarks into a directory on your machine and set the following variable to the path of that directory.\n",
    "BENCHMARKS_DIR = './datasets/'\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_code import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from model_code.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2e8a6-63e3-4a7b-a131-87ac663c7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BENCHMARK_NAME = 'DBP_Predict_refine_13289_230726'\n",
    "\n",
    "# A local (non-global) bianry output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.04, random_state = 0)\n",
    "\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, 'DBP_Predict_PDB.test.csv')\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "        seq_len = 256, batch_size = 32, max_epochs_per_stage =10, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "\n",
    "# Evaluating the performance on the test-set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd05814-c0f9-4764-b397-3a4717faedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test,y_preds,y_trues,results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['protein_ID'],test_set['seq'], test_set['label'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "\n",
    "dataframe_512 = pd.DataFrame()\n",
    "dataframe_1024 = pd.DataFrame()\n",
    "dataframe_2048 = pd.DataFrame()\n",
    "\n",
    "\n",
    "dataframe_512['protein_ID'] = X_test[0]\n",
    "dataframe_512['y_preds'] = y_preds[0]\n",
    "dataframe_512['y_trues'] = y_trues[0]\n",
    "dataframe_1024['protein_ID'] = X_test[1]\n",
    "dataframe_1024['y_preds'] = y_preds[1]\n",
    "dataframe_1024['y_trues'] = y_trues[1]\n",
    "dataframe_2048['protein_ID'] = X_test[2]\n",
    "dataframe_2048['y_preds'] = y_preds[2]\n",
    "dataframe_2048['y_trues'] = y_trues[2]\n",
    "\n",
    "dataframe = pd.concat([dataframe_512,dataframe_1024,dataframe_2048])\n",
    "\n",
    "dataframe.to_csv('./PLM-DBPPred_predict_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147b714-748f-44f4-97b2-97edcd4ffa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix,precision_score,recall_score,f1_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred = np.array(dataframe['y_preds'])\n",
    "# print(y_pred)\n",
    "\n",
    "y_true = dataframe['y_trues'].values\n",
    "\n",
    "y_pred_classes = (y_pred >= 0.5)\n",
    "y_true_classes = (y_true >= 0.5)\n",
    "\n",
    "# print(y_pred_classes)\n",
    "# print(y_true_classes)\n",
    "results = pd.DataFrame()\n",
    "results['AUC'] = [roc_auc_score(y_true, y_pred)]\n",
    "results['Accuracy'] = [accuracy_score(y_true, y_pred_classes)]\n",
    "results['precision'] = [precision_score(y_true, y_pred_classes)]\n",
    "results['recall_score'] = [recall_score(y_true, y_pred_classes)]\n",
    "results['f1_score'] = [f1_score(y_true, y_pred_classes)]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true,y_pred_classes).ravel()\n",
    "\n",
    "results['sensitivity'] = [tp / (tp + fn)]\n",
    "results['specificity'] = [tn / (tn + fp)]\n",
    "\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix(y_true,y_pred_classes))\n",
    "confusion_matrix\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af208ec-cf2f-440a-b9d7-403f46d46dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1db51-f7f7-4011-b2b1-7f8546007cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./DBP_model_param/model.pt', 'wb') as f:\n",
    "    pickle.dump(model_generator, f)\n",
    "\n",
    "with open('./DBP_model_param/model_OUTPUT_SPEC.pt', 'wb') as f:\n",
    "    pickle.dump(OUTPUT_SPEC, f)\n",
    "\n",
    "with open('./DBP_model_param/model_input_encoder.pt', 'wb') as f:\n",
    "    pickle.dump(input_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b542d3-2452-4bdd-a4f4-6af63a99339c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d2cc2-e54a-4b9e-9f84-def80f45913a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“alphafold_2”",
   "language": "python",
   "name": "alphafold_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
